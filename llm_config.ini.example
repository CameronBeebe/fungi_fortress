[LLM]
# === API KEY CONFIGURATION ===
# API keys are loaded from environment variables for security
# Set these environment variables in your shell or .env file:
#
# For XAI (Grok):     export XAI_API_KEY="your-xai-api-key-here"
# For OpenAI:         export OPENAI_API_KEY="your-openai-api-key-here"
# For Anthropic:      export ANTHROPIC_API_KEY="your-anthropic-api-key-here"
# For Groq:           export GROQ_API_KEY="your-groq-api-key-here"
# For Together:       export TOGETHER_API_KEY="your-together-api-key-here"
# For Perplexity:     export PERPLEXITY_API_KEY="your-perplexity-api-key-here"
#
# The system will automatically detect which API key to use based on your chosen provider

# LLM Provider (auto, xai, groq, openai, anthropic, together, perplexity)
# auto = automatically detect based on model name
provider = auto

# Model to use - depends on your chosen provider:
#
# XAI (Grok models):
#   grok-3, grok-3-beta, grok-2-1212, grok-beta, grok-vision-beta, grok-3-mini, grok-3-mini-fast
#
# Groq (fast open-source models):
#   llama-3.3-70b-versatile, llama-3.1-8b-instant, gemma2-9b-it, mixtral-8x7b-32768
#
# OpenAI:
#   gpt-4o, gpt-4o-mini, gpt-4-turbo, gpt-3.5-turbo
#
# Anthropic:
#   claude-3-5-sonnet-20241022, claude-3-5-haiku-20241022, claude-3-opus-20240229
#
# Together:
#   meta-llama/Llama-3.2-90B-Vision-Instruct-Turbo, meta-llama/Llama-3.1-70B-Instruct-Turbo
#
# Perplexity:
#   llama-3.1-sonar-small-128k-online, llama-3.1-sonar-large-128k-online
model_name = gpt-4o-mini

# Context detail level for game state information (low, medium, high)
context_level = medium

# === COST CONTROL & SAFETY SETTINGS ===
# These settings help prevent runaway API costs and ensure reliable operation

# Maximum tokens per response (1-4000, default: 500)
# Lower values reduce cost but may truncate responses
# NOTE: grok-3-mini requires at least 500 tokens to produce output
max_tokens = 1000

# API request timeout in seconds (1-120, default: 30)
# Prevents hanging requests that could block the game
timeout_seconds = 60

# Maximum retry attempts on failure (0-5, default: 2)
# Higher values improve reliability but may increase costs on persistent failures
max_retries = 2

# Delay between retry attempts in seconds (0.1-10.0, default: 1.0)
# Uses exponential backoff (delay * 2^attempt)
retry_delay_seconds = 1.0

# Daily request limit (1-1000, default: 100)
# Set to 0 to disable daily limiting entirely 
# Prevents excessive API usage and associated costs
# Set higher if you play frequently, lower for strict cost control
daily_request_limit = 0

# Enable detailed request logging (true/false, default: true)
# Logs all API requests for monitoring usage and debugging
enable_request_logging = true

# Enable XAI structured outputs (true/false, default: true)
# Uses JSON Schema to guarantee valid structured responses from XAI models
# This provides more reliable game action parsing compared to text parsing
enable_structured_outputs = false 